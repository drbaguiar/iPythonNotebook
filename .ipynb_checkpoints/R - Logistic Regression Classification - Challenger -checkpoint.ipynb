{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Space Shuttle O-Ring Failures - Logistic Regression Example\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Clear the environment\n",
    "rm(list=ls())\n",
    "\n",
    "##Turn off scientific notations for numbers\n",
    "options(scipen = 999)  \n",
    "\n",
    "##Set locale\n",
    "Sys.setlocale(\"LC_ALL\", \"English\") \n",
    "\n",
    "##Set seed for reproducibility\n",
    "set.seed(2345)\n",
    "\n",
    "# Turn off warnings\n",
    "options(warn = -1)\n",
    "\n",
    "getstats <- function(cm){\n",
    "  # Sensititvity a.k.a TPR\n",
    "  tpr <-cm[2,2]/(cm[2,2]+cm[2,1])\n",
    "  fpr <-cm[1,2]/(cm[1,2]+cm[1,1])\n",
    "  \n",
    "  # Specificity a.k.a. TNR\n",
    "  tnr <- cm[1,1]/(cm[1,1]+cm[1,2])\n",
    "  fnr <- cm[2,1]/(cm[2,1]+cm[2,2])\n",
    "  \n",
    "  # Calculate accuracy\n",
    "  acc <-(cm[2,2]+cm[1,1])/sum(cm)\n",
    "  err <-(cm[1,2]+cm[2,1])/sum(cm)\n",
    "  \n",
    "  #Precision - Positive Predictive Value\n",
    "  ppv <- cm[2,2]/(cm[2,2]+cm[1,2])\n",
    "  \n",
    "  # Negative Predictive Value\n",
    "  npv <- cm[1,1]/(cm[1,1]+cm[2,1])\n",
    "  \n",
    "  rbind(TruePos_Sensitivity=tpr, FalsePos=fpr, TrueNeg_Specificty=tnr, FalseNeg=fnr, PositivePredictiveValue=ppv, NegativePredictiveValue=npv, Accuracy = acc, Error = err)\n",
    "}\n",
    "\n",
    "# clean the data names and data\n",
    "# Use: df<-cleanit(df)\n",
    "cleanit <-function(df){\n",
    "  names(df) <-tolower(names(df))\n",
    "  names(df) <- gsub(\"\\\\(\",\"\",names(df))\n",
    "  names(df) <- gsub(\"\\\\)\",\"\",names(df))\n",
    "  names(df) <- gsub(\"\\\\.\",\"\",names(df))\n",
    "  names(df) <- gsub(\"_\",\"\",names(df))\n",
    "  names(df) <- gsub(\"-\",\"\",names(df))\n",
    "  names(df) <- gsub(\",\",\"\",names(df))\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "\n",
    "thres=.3 # Start at 50%\n",
    "nbrclust = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data\n",
    "\n",
    "On January 27, 1986, the night before the space shuttle Challenger exploded, engineers at the company that built the shuttle warned National Aeronautics and Space Administration (NASA) scientists that the shuttle should not be launched because of predicted cold weather. Fuel seal problems, which had been encountered in earlier flights, were suspected of being associated with low temperatures. It was argued, that the evidence was inconclusive. The decision was made to launch, even though the temperature at launch time was 29 F.\n",
    "\n",
    "The data consists of temperatures (degrees Fahrenheit) and an indicator of O-ring failures for 24 space shuttle launches prior to the Challenger disaster. The data in this example comes from Kelly, D. L., & Smith, C. L., (2008). “Risk Analysis of the Space Shuttle: Pre-Challenger Bayesian Prediction of Failure,” NASA Space Systems Engineering & Risk Management Symposium https://inldigitallibrary.inl.gov/sti/3901032.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Build dataframe\n",
    "flt<-c('1','2','3','4','5','6','7','8','9','41-B','41-C','41-D','41-G','51-A','51-C','51-D','51-B','51-G','51-F','51-I','51-J','61-A','61-B','61-C')\n",
    "temp<-c(66,70,69,80,68,67,72,73,70,57,63,70,78,67,53,67,75,70,81,76,79,75,76,58)\n",
    "damage<-c(0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,1,0,1)\n",
    "df<-data.frame(flt,temp,damage)\n",
    "rm(temp)\n",
    "rm(damage)\n",
    "rm(flt)\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(df)\n",
    "sapply(df, mean)\n",
    "sapply(df,sd)\n",
    "\n",
    "## two-way contingency table of categorical outcome and predictors\n",
    "xtabs(~damage + temp, data = df)\n",
    "\n",
    "## Correlation Matrix for numeric variables\n",
    "cor(df[,c(2:3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "hist(df$temp)\n",
    "boxplot(df$temp)\n",
    "hist(df$damage)\n",
    "boxplot(df$damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Enhanced Scatter plot\n",
    "# Add boxplots to a scatterplot\n",
    "par(fig=c(0,0.8,0,0.8), new=TRUE)\n",
    "plot(df$temp, df$damage, xlab=\"Temp\",  ylab=\"Failure\")\n",
    "#X Variable\n",
    "par(fig=c(0,0.8,0.55,1), new=TRUE)\n",
    "boxplot(df$temp, horizontal=TRUE, axes=FALSE)\n",
    "# Y Variable\n",
    "par(fig=c(0.65,1,0,0.8),new=TRUE)\n",
    "boxplot(df$damage, axes=FALSE)\n",
    "mtext(\"Enhanced Scatterplot\", side=3, outer=TRUE, line=-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline on Training data \n",
    "# Determine the Majority\n",
    "bl <-table(df$damage)\n",
    "majority<-ifelse(bl[1]>bl[2],0,1)\n",
    "\n",
    "# Fill in a prediction for the majority\n",
    "predictTrainBase <-rep(majority,nrow(df))\n",
    "#Compare\n",
    "cm <- table(df$damage,predictTrainBase, exclude=NULL)\n",
    "addmargins(cm)\n",
    "getstats(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline based on Majority a.k.a. Naive Baseline\n",
    "# Determine the Majority\n",
    "#table(df$damage)\n",
    "majority<- ifelse(table(df$damage)[[1]]>table(df$damage)[[2]], 0, 1)\n",
    "\n",
    "# Fill in a prediction\n",
    "predictBase <-rep(majority,nrow(df))\n",
    "\n",
    "#Compare\n",
    "table(df$damage,predictBase, exclude=NULL)\n",
    "cm <- table(df$damage,predictBase, exclude=NULL)\n",
    "addmargins(cm)\n",
    "getstats(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pull Out Errors\n",
    "\n",
    "#### False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out mistakes\n",
    "subset(df, predictBase >= thres & damage == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset(df,  predictBase <= thres & damage == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Build a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model Dep and Independent Vars define columns we will be working with\n",
    "depvar <- 'damage'\n",
    "indepvars <-c('temp')\n",
    "vars<- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit the simple model\n",
    "fit01<-glm(vars,data=df,family=binomial(logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Review Output\n",
    "summary(fit01) # display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, the first thing we see is the call which is reminding us what the model we ran was, what options we specified, etc.\n",
    "\n",
    "Next we see the deviance residuals, which are a measure of model fit. This part of output shows the distribution of the deviance residuals for individual cases used in the model. \n",
    "\n",
    "The next part of the output shows the coefficients, their standard errors, the z-statistic (sometimes called a Wald z-statistic), and the associated p-values.  The logistic regression coefficients give the change in the log odds of the outcome for a one change in the predictor variable.  \n",
    "    \n",
    "    In this example, we see temp is statistically significant. \n",
    "    For every one unit increase in temp, the log odds of failure (versus non-failure) decreases by 0.2360\n",
    "\n",
    "Below the table of coefficients are fit indices, including the null and deviance residuals and the AIC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Confidence Intervals\n",
    "\n",
    "We can use the confint function to obtain confidence intervals for the coefficient estimates. Note that for logistic models, confidence intervals are based on the profiled log-likelihood function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CIs using profiled log-likelihood\n",
    "# 95% CI for the coefficients\n",
    "# If the confidence interval contains 1, the results are not statisticlly significant\n",
    "confint(fit01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get CIs based on just the standard errors by using the default method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CIs using standard errors\n",
    "# 95% CI for the coefficients\n",
    "# If the confidence interval contains 1, the results are not statisticlly significant\n",
    "confint.default(fit01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it all in one table, we use cbind to bind the coefficients and confidence intervals column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbind(Log_Like = coef(fit01), confint(fit01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbind(Log_Like = coef(fit01), confint.default(fit01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Odds Ratio\n",
    "\n",
    "Odds ratios are used to compare the relative odds of the occurrence of the outcome of interest (e.g. disease or disorder), given exposure to the variable of interest (e.g. health characteristic, aspect of medical history). The odds ratio can also be used to determine whether a particular exposure is a risk factor for a particular outcome, and to compare the magnitude of various risk factors for that outcome.\n",
    "\n",
    "    OR=1 Exposure does not affect odds of outcome\n",
    "    OR>1 Exposure associated with higher odds of outcome\n",
    "    OR<1 Exposure associated with lower odds of outcome\n",
    "\n",
    "\n",
    "We can exponentiate the coefficients and interpret them as odds-ratios. R will do this computation for you. To get the exponentiated coefficients, you tell R that you want to exponentiate (exp), and that the object you want to exponentiate is called coefficients and it is part of fit (coef(fit))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp(coef(fit01)) # exponentiated coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same logic to get odds ratios and their confidence intervals, by exponentiating the confidence intervals from before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp(confint(fit01)) # 95% CI for exponentiated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp(confint.default(fit01))# 95% CI for exponentiated coefficients using standard error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it all in one table, we use cbind to bind the coefficients and confidence intervals column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## odds ratios and 95% CI\n",
    "exp(cbind(OR = coef(fit01), confint(fit01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## odds ratios and 95% CI\n",
    "exp(cbind(OR = coef(fit01), confint.default(fit01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can say that for a one unit increase in temp, the odds of failure (versus non-failure ) decrease by a factor of .79. Note that while R produces it, the odds ratio for the intercept is not generally interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictTrain<-predict(fit01, type=\"response\") # predicted values\n",
    "#residuals(fit, type=\"deviance\") # residuals\n",
    "\n",
    "# Confusion Matrix\n",
    "#table(fit01$fitted.values>=thres,df$damage)\n",
    "cm <- table(df$damage,predictTrain>thres)\n",
    "addmargins(cm)\n",
    "getstats(cm)\n",
    "\n",
    "#Get all zeros correct 100% (TRUE NEGATIVE RATE)\n",
    "#Get 4 out of 7 ones correct 57% (TRUE POSITVE RATE)\n",
    "#Accuracy got 21 out of 24 correct 87.5%\n",
    "#Error got 3 out of 24 incorrect 12.5%\n",
    "#REMEMBER ACCuray is not a good measure of the woth of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pull Out Errors\n",
    "\n",
    "####False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset(df, predictTrain >= thres & damage == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset(df, predictTrain <= thres & damage == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Receiver Operator Charastics ROC\n",
    "library(ROCR)\n",
    "\n",
    "# Prediction function\n",
    "ROCRpredTest = prediction(predictTrain,df$damage)\n",
    "\n",
    "# Performance function\n",
    "ROCRperfTest = performance(ROCRpredTest, \"tpr\", \"fpr\")\n",
    "\n",
    "# Plot ROC curve and add AUC \n",
    "plot(ROCRperfTest, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))\n",
    "abline(coef=c(0,1))\n",
    "auc = as.numeric(performance(ROCRpredTest, \"auc\")@y.values)\n",
    "text(0.5, 1, \"AUC:\")\n",
    "text(0.6,1, round(auc,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of Thumb Intrepretations\n",
    "\n",
    "If the area under ROC is:\n",
    "    \n",
    "    No discrimination:         0.5  \n",
    "    Acceptable discrimination: 0.7 <= ROC area < 0.8 \n",
    "    Excellent discrimination:  0.8 <= ROC area < 0.9 \n",
    "    Outstanding discrimination ROC area >= 0.9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df <- transform (df,temp_scaled=scale(temp) )# standardize temp variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit02 <- kmeans(df$temp_scaled, nbrclust)\n",
    "\n",
    "# get cluster means \n",
    "aggregate(df$temp_scaled,by=list(fit02$cluster),FUN=mean)\n",
    "\n",
    "# append cluster assignment\n",
    "mydata <- data.frame(df$temp_scaled, fit02$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cluster Plot against 1st 2 principal components\n",
    "library(fpc)\n",
    "library(cluster) \n",
    "\n",
    "# vary parameters for most readable graph\n",
    "clusplot(df$temp_scaled, fit02$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)\n",
    "\n",
    "# Centroid Plot against 1st 2 discriminant functions\n",
    "plotcluster(df$temp_scaled, fit02$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotcluster(df$temp, fit02$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ward Hierarchical Clustering\n",
    "d <- dist(df$temp_scaled, method = \"euclidean\") # distance matrix\n",
    "fit03 <- hclust(d, method=\"ward.D2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(fit03) # display dendogram\n",
    "groups <- cutree(fit03, k=nbrclust) # cut tree into 5 clusters\n",
    "# draw dendogram with red borders around the 5 clusters \n",
    "rect.hclust(fit03, k=nbrclust, border=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load groups\n",
    "df$groups <- cutree(fit03, nbrclust) # cut tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggdata= aggregate(.~ groups, data=df, FUN=mean) # Aggregation by group and computation of the mean values\n",
    "proptemp=aggregate(damage~ groups, data=df, FUN=length) # Computation of the number of observations by group\n",
    "aggdata$nbr=proptemp$damage\n",
    "aggdata$proportion=(proptemp$damage)/sum(proptemp$damage) # Computation of the proportion by group\n",
    "aggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[order(df$group,decreasing=T),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[order(df$temp,decreasing=T),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbrclust = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
